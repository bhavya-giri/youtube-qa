{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e2dace1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pytube as pt\n",
    "from transformers import pipeline\n",
    "from huggingface_hub import model_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "632c7510",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ckpt = \"openai/whisper-small\"\n",
    "lang = \"en\"\n",
    "device = torch.device(\"mps\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2b006fbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b06340015467447bae592fe9b816b0be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/1.97k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "404ea6cdfade4c90b50e7ab87bd47598",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading model.safetensors:   0%|          | 0.00/967M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd85d73b91f04e798edfd1c4d63cafc5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)neration_config.json:   0%|          | 0.00/3.84k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b4997d7bff24abfa6415a673014c99a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/842 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "749f48b6733b4f4fb5c2bee27db042e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)olve/main/vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aff2719c17de4222b3f560afc0af0a24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)/main/tokenizer.json:   0%|          | 0.00/2.20M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "533e5766bc914996b7acc5e242a0cb11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)olve/main/merges.txt:   0%|          | 0.00/494k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0cf6f4d397f046f890c68095e0bbbad3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)main/normalizer.json:   0%|          | 0.00/52.7k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b0212bdc3f5495bb1079f2d5bcdc82b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)in/added_tokens.json:   0%|          | 0.00/2.08k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3c4f1c8f9674d78800be3a6c46e51d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/2.08k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c70ac2adfe2c4f7fa002c742723d2c90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)rocessor_config.json:   0%|          | 0.00/185k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pipe = pipeline(\n",
    "    task=\"automatic-speech-recognition\",\n",
    "    model=model_ckpt,\n",
    "    chunk_length_s=30,\n",
    "    device=device,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "75d8f712",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe.model.config.forced_decoder_ids = pipe.tokenizer.get_decoder_prompt_ids(language=lang, task=\"transcribe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f348702c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bhavyagiri/mambaforge/lib/python3.10/site-packages/transformers/generation/utils.py:1369: UserWarning: Using `max_length`'s default (448) to control the generation length. This behaviour is deprecated and will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n",
      "/Users/bhavyagiri/mambaforge/lib/python3.10/site-packages/transformers/generation/utils.py:2419: UserWarning: MPS: no support for int64 min/max ops, casting it to int32 (Triggered internally at /Users/runner/work/_temp/anaconda/conda-bld/pytorch_1682343686130/work/aten/src/ATen/native/mps/operations/ReduceOps.mm:1271.)\n",
      "  if unfinished_sequences.max() == 0:\n"
     ]
    }
   ],
   "source": [
    "yt_url = \"https://www.youtube.com/watch?v=I2ZK3ngNvvI\" \n",
    "yt = pt.YouTube(yt_url)\n",
    "stream = yt.streams.filter(only_audio=True)[0]\n",
    "stream.download(filename=\"audio.mp3\")\n",
    "text = pipe(\"audio.mp3\")[\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "58d1f382",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" What advice would you give to beginners interested in. You literally have to put in 10,000 hours of work. It doesn't even like matter as much like where you put it and you'll iterate and you'll improve and you'll waste some time. I don't know if there's a better way. You need to put in 10,000 hours. But I think it's actually really nice because I feel like there's some sense of determinism about being an expert at a thing if you spend 10,000 hours. You can literally pick an arbitrary thing. And I think if you spend 10,000 hours of deliberate effort and work, you actually will become an expert at it. And so I think that's kind of like a nice thought. And so basically I would focus more on like, are you spending 10,000 hours? That's what I000 hours? So and then thinking about what kind of mechanisms maximize your likelihood of getting to 10,000 hours exactly which for us silly humans means probably forming a daily habit of like every single day actually doing the thing whatever helps you So I do think to a large extent is a psychological problem for yourself Yeah, one other thing that I help that I think is helpful for the psychology of it is many times people compare themselves to others in the area. I think it's very harmful. Only compare yourself to you from some time ago, like say a year ago. Are you better than you a year ago? It's the only way to think. And I think this, then you can see your progress and it's very motivating. That's so interesting that focused on the quantity of hours. I think a lot of people in the beginner stage but actually throughout get paralyzed by the choice. Like which one do I pick this path or this path? Yeah, like they'll literally get paralyzed by like which ID to use. Well, they're worried. Yeah, they'll worried about all these things. But the thing is some of the you will waste time doing something wrong. Yes. You will eventually figure out it's not right. You will accumulate scar tissue and next time you will grow stronger because next time you'll have the scar tissue and next time you'll learn from it. And now next time you come to a similar situation, you'll be like, oh, I messed up. I've spent a lot of time working on things that never materialize into anything. And I have all that scar tissue and I have some intuitions about what was useful, what wasn't useful, how things turned out. So all those mistakes were not dead work. So I just think you should, did you just focus on working? What have you done? What have you done last week? That's a good question actually to ask for a lot of things. That's just machine learning. It's a good way to cut the, I forgot what the term we used, but the fluff, the blubber, whatever the inefficiencies in life. What do you love about teaching? You seem to find yourself often in the, like draw into teaching. You're very good at it, but you're also drawn to it. I mean, I don't think I love teaching. I love happy humans. And happy humans like when I teach. I wouldn't say I hate teaching. I tolerate teaching, but it's not like the act of teaching that I like. It's that I have something. I'm actually okay at it. I'm okay at teaching and people appreciate it a lot. And so I'm just happy to happy to try to be helpful and teaching itself is not like the most, I mean, it's really, it's can be really annoying, frustrating. I was working on a bunch of lectures just now. I was reminded back to my days of 231 and just how much work it is to create some of these materials and make them good. The amount of iteration and thought and you go down blind alleys and just how much you change it. So creating something good in terms of like educational values really hard and it's not fun. It's difficult. So for people should definitely go watch your new stuff. You put out there are lectures where you actually building the thing like from like you said the code is truth. So discussing back propagation by building it by looking through and just the whole thing. So how difficult is that to prepare for? I think that's a really powerful way to teach. Did you have to prepare for that or are you just live thinking through it? I will typically do like say three takes and then I take like the better take. So I do multiple takes and I take some of the better takes and then I just build out a lecture that way. Sometimes I have to delete 30 minutes of content because it just went down the nally that I didn't like too much. There's a bunch of iteration and it probably takes me somewhere around 10 hours to create one hour of content. To get one hour. It's interesting. Is it difficult to go back to the basics? Do you draw a lot of wisdom from going back to the basics? Going back to back propagation, lost functions, where they come from and one thing I like about teaching a lot honestly is it definitely strengthens your understanding So it's not a purely altruistic activity It's a way to learn if you have to explain something to someone You realize you have gaps in knowledge And so I even surprised myself in those lectures like also the result will obviously look at this and then the result doesn't look like it and I'm like, okay, I thought I understood this. Yeah. That's why it's really cool. Literally code, you run it in a notebook and it gives you a result and you're like, oh, wow. And like actual numbers, actual input, actual code. Yeah, it's not mathematical symbols, et cetera. The source of truth is the code. It's not slides. It's just like, let's build it. It's beautiful. You're a rare human in that sense.\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
